{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c453b6-e44f-4c5f-bf21-a9fe25544c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(20000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 20 seconds\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%autosave 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6587582-4314-4f97-8efd-81b06eacdee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7fc264f-b9e6-4ab9-9238-b3537ec48a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "from optimizer import *\n",
    "from data_loader import *\n",
    "from run import *\n",
    "import torch\n",
    "from model import Net\n",
    "from optimizer import get_optimizer,run_lrfinder\n",
    "from model_fit import training,testing\n",
    "import albumentations as A\n",
    "from albumentations.augmentations.geometric.resize import Resize\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from data_loader import MNISTDataLoader\n",
    "import json\n",
    "from torch import nn\n",
    "import plotext as plt\n",
    "import torch\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR,ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from torch_lr_finder import LRFinder\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0540c353-4361-40d6-9c20-a5d566a2343a",
   "metadata": {},
   "source": [
    "model_o = Net().to('cuda')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2fc6f935-7f69-4f71-b9f6-09ab10ac9be8",
   "metadata": {},
   "source": [
    "summary(model_o,(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1816c78d-944d-40e5-b679-3358bbf75b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "371986d6-baf3-41d6-9b02-f32809f5dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['training']['epochs'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a96c7f42-df07-4b84-bfc4-2517c1469775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['training']['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9507e0f-e196-420d-904f-cc3434db36bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    # If using torch.backends.cudnn, set the following for reproducibility\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def get_model(device):\n",
    "    model = Net().to(device)\n",
    "    # model = model.float()\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_model(model,device,batch_size,epochs,optimizer,scheduler,use_scheduler,best_model):\n",
    "    train_losses = []\n",
    "    train_accuracy = []\n",
    "    test_losses =[]\n",
    "    test_accuracy = []\n",
    "    # print(scheduler)\n",
    "    # print(optimizer)\n",
    "    # summary(model, (1,28, 28 )).to(device)\n",
    "    _ = receptive_field(model,28)\n",
    "\n",
    "    for EPOCHS in range(0,epochs):\n",
    "        train_loss, train_acc = training(model,device,train_loader,optimizer,EPOCHS)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracy.append(train_acc)\n",
    "\n",
    "        test_loss,test_acc = testing(model,device,test_loader,EPOCHS)\n",
    "        test_accuracy.append(test_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        if (scheduler_type == 'reducelronplateau') & (use_scheduler ==True):\n",
    "            scheduler.step(test_loss)\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "        elif (scheduler_type == 'steplr') & (use_scheduler ==True):\n",
    "            scheduler.step()\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "        else:\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        try:\n",
    "            if len(test_accuracy) > 1:\n",
    "                if (EPOCHS >= 3 and \n",
    "                    max(test_accuracy[:-1]) < test_accuracy[-1] and \n",
    "                    max(test_accuracy) >= best_model):\n",
    "                    \n",
    "                    checkpoint = {\n",
    "                        'epoch': EPOCHS + 1,\n",
    "                        'valid_loss_min': test_losses[-1],\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                    }\n",
    "                    \n",
    "                    file_name = f\"./model_folder/modelbest_{test_accuracy[-1]:.4f}_epoch_{EPOCHS}.pt\"\n",
    "                    torch.save(checkpoint, file_name)\n",
    "                    print(f\"Target Achieved: {max(test_accuracy) * 100:.2f}% Test Accuracy!!\")\n",
    "                else:\n",
    "                    print(\"Conditions not met for saving the model.\")\n",
    "            else:\n",
    "                print(\"Insufficient test accuracy data.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Model saving failed: {e}\")\n",
    "\n",
    "        print(f\"LR: {current_lr}\\n\")\n",
    "    return model,train_losses, train_accuracy,test_losses,test_accuracy\n",
    "\n",
    "\n",
    "def load_config():\n",
    "    with open('config.json', 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def get_loss_function(loss_type):\n",
    "    if loss_type is None:\n",
    "        return nn.NLLLoss()   \n",
    "    loss_types = {\n",
    "        'cross_entropy': nn.CrossEntropyLoss(),\n",
    "        'mse': nn.MSELoss(),\n",
    "        'nll': nn.NLLLoss()\n",
    "    }\n",
    "    return loss_types.get(loss_type.lower(), nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c78352-3f79-449b-a6ac-ad88e7190e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "# Set seed from config\n",
    "set_seed(config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ed0b5f9-609f-4380-af0f-b40bc6269d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Get loss function and scheduler settings from config\n",
    "loss_fn = get_loss_function(config['training'].get('loss_type'))\n",
    "use_scheduler = config['training'].get('use_scheduler', False)\n",
    "scheduler_type = config['training'].get('scheduler_type', 'steplr')\n",
    "runlr_finer = config['training'].get('runlr_finer', False)\n",
    "use_scheduler = bool(use_scheduler)\n",
    "runlr_finer = bool(runlr_finer)\n",
    "\n",
    "best_model = config['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a178e72-b112-4075-9c1e-d1cd61cbd6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "NLLLoss()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'reducelronplateau'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.991"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n",
    "loss_fn\n",
    "use_scheduler\n",
    "scheduler_type\n",
    "runlr_finer\n",
    "use_scheduler\n",
    "runlr_finer\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2165da4c-094a-4967-bb87-69d5ee90064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed from config\n",
    "_ = torch.manual_seed(config['seed'])\n",
    "if torch.cuda.is_available():\n",
    "    _ = torch.cuda.manual_seed(config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b9b15be-0231-4ed2-b5f1-2999587c395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get batch size based on device\n",
    "batch_size = config['training']['batch_size']\n",
    "epochs = config['training']['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1b2c95b-8191-43d8-b3d4-c8eaf9ee704f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25273845-c61b-4cbb-a08b-f2adf076cd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.1307 Std: 0.3081\n"
     ]
    }
   ],
   "source": [
    "model = get_model(device)\n",
    "data_loader = MNISTDataLoader(batch_size=batch_size)\n",
    "train_loader, test_loader = data_loader.get_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1eecbf0-f231-4d0a-bda9-5d3e0ff2d18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: .data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(28, 28), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               ColorJitter(brightness=(0.9, 1.1), contrast=(0.9, 1.1), saturation=(0.9, 1.1), hue=(-0.1, 0.1))\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d16f21ff-e425-449f-bb16-c69c880deb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: .data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(28, 28), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a31adf4-142f-472b-b5d8-99e7ceedfe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if runlr_finer:\n",
    "    lrs,_ = run_lrfinder(\n",
    "        model, \n",
    "        device, \n",
    "        train_loader, \n",
    "        test_loader, \n",
    "        start_lr=config['training']['start_lr'],\n",
    "        end_lr=config['training']['end_lr'],\n",
    "            lr_iter=config['training'].get('lr_iter', 1000)\n",
    "        )\n",
    "    print(lrs)\n",
    "else:\n",
    "    lrs = [0.015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74d45a8c-7e3c-458b-a00d-4b29e77a6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer,scheduler = get_optimizer(model,scheduler = use_scheduler,\\\n",
    "                          scheduler_type = scheduler_type,lr = lrs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ef9f39f-0542-48cc-9330-223053a3ce44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.015\n",
       "    maximize: False\n",
       "    momentum: 0.9\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a666feb-0a84-4712-a482-00818b3b95a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 26, 26]              90\n",
      "       BatchNorm2d-2           [-1, 10, 26, 26]              20\n",
      "              ReLU-3           [-1, 10, 26, 26]               0\n",
      "           Dropout-4           [-1, 10, 26, 26]               0\n",
      "            Conv2d-5           [-1, 10, 24, 24]             900\n",
      "       BatchNorm2d-6           [-1, 10, 24, 24]              20\n",
      "              ReLU-7           [-1, 10, 24, 24]               0\n",
      "           Dropout-8           [-1, 10, 24, 24]               0\n",
      "            Conv2d-9           [-1, 15, 22, 22]           1,350\n",
      "      BatchNorm2d-10           [-1, 15, 22, 22]              30\n",
      "             ReLU-11           [-1, 15, 22, 22]               0\n",
      "          Dropout-12           [-1, 15, 22, 22]               0\n",
      "        MaxPool2d-13           [-1, 15, 11, 11]               0\n",
      "           Conv2d-14           [-1, 10, 11, 11]             150\n",
      "      BatchNorm2d-15           [-1, 10, 11, 11]              20\n",
      "             ReLU-16           [-1, 10, 11, 11]               0\n",
      "          Dropout-17           [-1, 10, 11, 11]               0\n",
      "           Conv2d-18             [-1, 10, 9, 9]             900\n",
      "      BatchNorm2d-19             [-1, 10, 9, 9]              20\n",
      "             ReLU-20             [-1, 10, 9, 9]               0\n",
      "          Dropout-21             [-1, 10, 9, 9]               0\n",
      "           Conv2d-22             [-1, 10, 7, 7]             900\n",
      "      BatchNorm2d-23             [-1, 10, 7, 7]              20\n",
      "             ReLU-24             [-1, 10, 7, 7]               0\n",
      "          Dropout-25             [-1, 10, 7, 7]               0\n",
      "           Conv2d-26             [-1, 10, 5, 5]             900\n",
      "      BatchNorm2d-27             [-1, 10, 5, 5]              20\n",
      "             ReLU-28             [-1, 10, 5, 5]               0\n",
      "          Dropout-29             [-1, 10, 5, 5]               0\n",
      "           Conv2d-30             [-1, 10, 1, 1]           2,500\n",
      "================================================================\n",
      "Total params: 7,840\n",
      "Trainable params: 7,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.70\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.73\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "785647fa-92bb-4cce-b955-50fe70731c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    momentum: 0.9\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5813064-6771-42e7-ae1f-c4cecf2a9f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model,train_losses, train_accuracy,test_losses,test_accuracy= run_model(model,device,batch_size,epochs,optimizer,scheduler,use_scheduler,best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574db322-4cd2-40ab-847d-bdb8d52fc63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================Reciptive Field Calculator========================================\n",
      "|    | Kernel_size   | Padding   |   Stride | Input_Img_size   | Output_Img_size   | Receptive_field   |\n",
      "|---:|:--------------|:----------|---------:|:-----------------|:------------------|:------------------|\n",
      "|  0 | 3*3           | NO        |        1 | 28*28            | 26*26             | 3*3               |\n",
      "|  1 | 3*3           | NO        |        1 | 26*26            | 24*24             | 5*5               |\n",
      "|  2 | 3*3           | NO        |        1 | 24*24            | 22*22             | 7*7               |\n",
      "|  3 | 2*2           | NO        |        2 | 22*22            | 11*11             | 8*8               |\n",
      "|  4 | 1*1           | NO        |        1 | 11*11            | 11*11             | 8*8               |\n",
      "|  5 | 3*3           | NO        |        1 | 11*11            | 9*9               | 12*12             |\n",
      "|  6 | 3*3           | NO        |        1 | 9*9              | 7*7               | 16*16             |\n",
      "|  7 | 3*3           | NO        |        1 | 7*7              | 5*5               | 20*20             |\n",
      "|  8 | 5*5           | NO        |        1 | 5*5              | 1*1               | 28*28             |\n",
      "=========================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 0 Batch:  468 loss: 0.3084717094898224 Accuracy: 78.57% : 100%|\u001b[33m█\u001b[0m| 469/469 [0\u001b[0m\n",
      "Test ==> Epochs: 0 Batch:  78 loss: 0.23437826504707338 Accuracy: 94.59% : 100%|█| 79/79 [00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insufficient test accuracy data.\n",
      "LR: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 1 Batch:  468 loss: 0.1329829841852188 Accuracy: 94.90% : 100%|\u001b[33m█\u001b[0m| 469/469 [0\u001b[0m\n",
      "Test ==> Epochs: 1 Batch:  78 loss: 0.12610795253515245 Accuracy: 96.80% : 100%|█| 79/79 [00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditions not met for saving the model.\n",
      "LR: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 2 Batch:  468 loss: 0.057398125529289246 Accuracy: 96.50% : 100%|\u001b[33m█\u001b[0m| 469/469 \u001b[0m\n",
      "Test ==> Epochs: 2 Batch:  78 loss: 0.09328715511262417 Accuracy: 97.44% : 100%|█| 79/79 [00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditions not met for saving the model.\n",
      "LR: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 3 Batch:  468 loss: 0.1131010353565216 Accuracy: 97.20% : 100%|\u001b[33m█\u001b[0m| 469/469 [0\u001b[0m\n",
      "Test ==> Epochs: 3 Batch:  78 loss: 0.07599667673707008 Accuracy: 97.73% : 100%|█| 79/79 [00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditions not met for saving the model.\n",
      "LR: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 4 Batch:  468 loss: 0.14480708539485931 Accuracy: 97.65% : 100%|\u001b[33m█\u001b[0m| 469/469 [\u001b[0m\n",
      "Test ==> Epochs: 4 Batch:  78 loss: 0.06512857909202575 Accuracy: 98.10% : 100%|█| 79/79 [00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditions not met for saving the model.\n",
      "LR: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 5 Batch:  468 loss: 0.05354567989706993 Accuracy: 97.96% : 100%|\u001b[33m█\u001b[0m| 469/469 [\u001b[0m\n",
      "Test ==> Epochs: 5 Batch:  78 loss: 0.06140730735063553 Accuracy: 98.14% : 100%|█| 79/79 [00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditions not met for saving the model.\n",
      "LR: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 6 Batch:  468 loss: 0.12068238854408264 Accuracy: 98.11% : 100%|\u001b[33m█\u001b[0m| 469/469 [\u001b[0m\n",
      "Test ==> Epochs: 6 Batch:  78 loss: 0.05524057883620262 Accuracy: 98.31% : 100%|█| 79/79 [00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditions not met for saving the model.\n",
      "LR: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 7 Batch:  468 loss: 0.03358926251530647 Accuracy: 98.28% : 100%|\u001b[33m█\u001b[0m| 469/469 [\u001b[0m\n",
      "Test ==> Epochs: 7 Batch:  78 loss: 0.04996420545578003 Accuracy: 98.48% : 100%|█| 79/79 [00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditions not met for saving the model.\n",
      "LR: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 8 Batch:  468 loss: 0.011604742147028446 Accuracy: 98.36% : 100%|\u001b[33m█\u001b[0m| 469/469 \u001b[0m\n",
      "Test ==> Epochs: 8 Batch:  78 loss: 0.046184641867876054 Accuracy: 98.54% : 100%|█| 79/79 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditions not met for saving the model.\n",
      "LR: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 9 Batch:  468 loss: 0.0998067557811737 Accuracy: 98.53% : 100%|\u001b[33m█\u001b[0m| 469/469 [0\u001b[0m\n",
      "Test ==> Epochs: 9 Batch:  78 loss: 0.04264759685993195 Accuracy: 98.63% : 100%|█| 79/79 [00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditions not met for saving the model.\n",
      "LR: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 10 Batch:  468 loss: 0.025904139503836632 Accuracy: 98.58% : 100%|\u001b[33m█\u001b[0m| 469/469\u001b[0m\n",
      "Test ==> Epochs: 10 Batch:  78 loss: 0.04307640072107315 Accuracy: 98.56% : 100%|█| 79/79 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditions not met for saving the model.\n",
      "LR: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 11 Batch:  468 loss: 0.07914740592241287 Accuracy: 98.60% : 100%|\u001b[33m█\u001b[0m| 469/469 \u001b[0m\n",
      "Test ==> Epochs: 11 Batch:  78 loss: 0.039770646174252036 Accuracy: 98.76% : 100%|█| 79/79 [00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditions not met for saving the model.\n",
      "LR: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 12 Batch:  468 loss: 0.022780127823352814 Accuracy: 98.68% : 100%|\u001b[33m█\u001b[0m| 469/469\u001b[0m\n",
      "Test ==> Epochs: 12 Batch:  78 loss: 0.03885299431756139 Accuracy: 98.68% : 100%|█| 79/79 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditions not met for saving the model.\n",
      "LR: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 13 Batch:  468 loss: 0.04736688733100891 Accuracy: 98.75% : 100%|\u001b[33m█\u001b[0m| 469/469 \u001b[0m\n",
      "Test ==> Epochs: 13 Batch:  78 loss: 0.039087547039985654 Accuracy: 98.84% : 100%|█| 79/79 [00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditions not met for saving the model.\n",
      "LR: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train ==> Epochs: 14 Batch:  460 loss: 0.032683372497558594 Accuracy: 98.82% :  98%|\u001b[33m▉\u001b[0m| 461/469\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 18\u001b[0m\n\u001b[1;32m     13\u001b[0m     lrs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.001\u001b[39m]\n\u001b[1;32m     15\u001b[0m optimizer,scheduler \u001b[38;5;241m=\u001b[39m get_optimizer(model,scheduler \u001b[38;5;241m=\u001b[39m use_scheduler,\\\n\u001b[1;32m     16\u001b[0m                           scheduler_type \u001b[38;5;241m=\u001b[39m scheduler_type,lr \u001b[38;5;241m=\u001b[39m lrs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 18\u001b[0m model,train_losses, train_accuracy,test_losses,test_accuracy\u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax Train Accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mmax\u001b[39m(train_accuracy))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax Test Accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mmax\u001b[39m(test_accuracy))\n",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(model, device, batch_size, epochs, optimizer, scheduler, use_scheduler, best_model)\u001b[0m\n\u001b[1;32m     26\u001b[0m _ \u001b[38;5;241m=\u001b[39m receptive_field(model,\u001b[38;5;241m28\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m EPOCHS \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,epochs):\n\u001b[0;32m---> 29\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     31\u001b[0m     train_accuracy\u001b[38;5;241m.\u001b[39mappend(train_acc)\n",
      "File \u001b[0;32m~/Desktop/ERA/Mnist_ops/model_fit.py:27\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, device, train_data, optimizer, epochs, scheduler)\u001b[0m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     25\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(train_data,colour \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYELLOW\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindex_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/era_n/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/era_n/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/era_n/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/era_n/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1283\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1283\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1284\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1285\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/era_n/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/era_n/lib/python3.12/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/miniconda3/envs/era_n/lib/python3.12/threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Max Train Accuracy: \",max(train_accuracy))\n",
    "print(\"Max Test Accuracy: \",max(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc61af-2176-4858-8267-a52b6a9e0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Create a figure with 1 row and 2 columns of subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))  # Adjust figsize as needed\n",
    "\n",
    "# Plot accuracy on the first subplot\n",
    "axes[0].plot(train_accuracy, label=\"Train Accuracy\")\n",
    "axes[0].plot(test_accuracy, label=\"Test Accuracy\")\n",
    "axes[0].set_title(\"Model Accuracy\")\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Accuracy\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot loss on the second subplot\n",
    "axes[1].plot(train_losses, label=\"Train Loss\")\n",
    "axes[1].plot(test_losses, label=\"Test Loss\")\n",
    "axes[1].set_title(\"Model Loss\")\n",
    "axes[1].set_xlabel(\"Epochs\")\n",
    "axes[1].set_ylabel(\"Loss\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e9254f-95c2-4ddf-b783-e04d03d4a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbcc746-62a7-4c63-90e6-e79a662980b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -R .github/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e2cf44-f7cc-4e0b-a342-f6a8b48a8970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
