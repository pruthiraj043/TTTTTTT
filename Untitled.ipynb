{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73926e0-5e7a-43aa-8399-67687d9c17a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(20000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 20 seconds\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%autosave 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab0d26b-8d02-4003-81cd-151e43230996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b13e1f-2e7d-46bd-b8a7-3f7e4eb6c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "                                       transforms.Resize((28, 28)),\n",
    "                                       transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
    "                                       ])       \n",
    "data1_transforms = transforms.Compose([\n",
    "                                       transforms.Resize((28, 28)),\n",
    "                                    #    transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
    "                                       ]) \n",
    "train = datasets.MNIST('.data', train=True, download=True,transform=data_transforms)\n",
    "test = datasets.MNIST('.data', train=False, download=True,transform=data1_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfc4d4b8-f96c-40dd-8e6c-a8db2e418826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: .data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(28, 28), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               ColorJitter(brightness=(0.9, 1.1), contrast=(0.9, 1.1), saturation=(0.9, 1.1), hue=(-0.1, 0.1))\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56101ef0-49bd-4236-90d8-629511d6340e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: .data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(28, 28), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31530609-dd30-4d04-80fc-247482ac2a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available? True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x756c6b5bab70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "batch_size = 64\n",
    "learning_rate = 0.015\n",
    "\n",
    "SEED = 3\n",
    "\n",
    "# is cuda available\n",
    "cuda = torch.cuda.is_available()\n",
    "print(\"CUDA Available?\", cuda)\n",
    "\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e84874-c538-4ab8-86e4-3c19e4541a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "  torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# dataloader arguments\n",
    "dataloader_args = dict(shuffle = True, batch_size = batch_size, num_workers = 4,pin_memory = True) if cuda else dict(shuffle = True, batch_size = 64)\n",
    "\n",
    "# train dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train, ** dataloader_args)\n",
    "\n",
    "# test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2843c5f8-ddbb-4bc4-91a3-d8a66c411830",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_value = 0.03\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Input Block\n",
    "        self.convblock1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # input_size = 28 output_size = 26 receptive_field = 3\n",
    "\n",
    "        # CONVOLUTION BLOCK 1\n",
    "        self.convblock2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # input_size = 26 output_size = 24 receptive_field = 5\n",
    "        self.convblock3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=15, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(15),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # input_size = 24 output_size = 22 receptive_field = 7\n",
    "\n",
    "        # TRANSITION BLOCK 1\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # input_size = 22 output_size = 11 receptive_field = 9\n",
    "        \n",
    "        self.convblock4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=15, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # input_size = 11 output_size = 11 receptive_field = 9\n",
    "\n",
    "        # CONVOLUTION BLOCK 2\n",
    "        self.convblock5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # input_size = 11 output_size = 9 receptive_field = 13\n",
    "        self.convblock6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # input_size = 9 output_size = 7 receptive_field = 17\n",
    "        self.convblock7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        ) # input_size = 7 output_size = 5 receptive_field = 21\n",
    "        # OUTPUT BLOCK\n",
    "        self.convblock8 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(5, 5), padding=0, bias=False),\n",
    "        ) # input_size = 5 output_size = 1  receptive_field = 29\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convblock1(x)\n",
    "        x = self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.convblock4(x)\n",
    "        x = self.convblock5(x)\n",
    "        x = self.convblock6(x)\n",
    "        x = self.convblock7(x)\n",
    "        x = self.convblock8(x)\n",
    "        \n",
    "        x = x.view(-1, 10)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cee62f88-d664-4c73-834c-178c7752bb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 26, 26]              90\n",
      "       BatchNorm2d-2           [-1, 10, 26, 26]              20\n",
      "              ReLU-3           [-1, 10, 26, 26]               0\n",
      "           Dropout-4           [-1, 10, 26, 26]               0\n",
      "            Conv2d-5           [-1, 10, 24, 24]             900\n",
      "       BatchNorm2d-6           [-1, 10, 24, 24]              20\n",
      "              ReLU-7           [-1, 10, 24, 24]               0\n",
      "           Dropout-8           [-1, 10, 24, 24]               0\n",
      "            Conv2d-9           [-1, 15, 22, 22]           1,350\n",
      "      BatchNorm2d-10           [-1, 15, 22, 22]              30\n",
      "             ReLU-11           [-1, 15, 22, 22]               0\n",
      "          Dropout-12           [-1, 15, 22, 22]               0\n",
      "        MaxPool2d-13           [-1, 15, 11, 11]               0\n",
      "           Conv2d-14           [-1, 10, 11, 11]             150\n",
      "      BatchNorm2d-15           [-1, 10, 11, 11]              20\n",
      "             ReLU-16           [-1, 10, 11, 11]               0\n",
      "          Dropout-17           [-1, 10, 11, 11]               0\n",
      "           Conv2d-18             [-1, 10, 9, 9]             900\n",
      "      BatchNorm2d-19             [-1, 10, 9, 9]              20\n",
      "             ReLU-20             [-1, 10, 9, 9]               0\n",
      "          Dropout-21             [-1, 10, 9, 9]               0\n",
      "           Conv2d-22             [-1, 10, 7, 7]             900\n",
      "      BatchNorm2d-23             [-1, 10, 7, 7]              20\n",
      "             ReLU-24             [-1, 10, 7, 7]               0\n",
      "          Dropout-25             [-1, 10, 7, 7]               0\n",
      "           Conv2d-26             [-1, 10, 5, 5]             900\n",
      "      BatchNorm2d-27             [-1, 10, 5, 5]              20\n",
      "             ReLU-28             [-1, 10, 5, 5]               0\n",
      "          Dropout-29             [-1, 10, 5, 5]               0\n",
      "           Conv2d-30             [-1, 10, 1, 1]           2,500\n",
      "================================================================\n",
      "Total params: 7,840\n",
      "Trainable params: 7,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.70\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.73\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "model = Net().to(device)\n",
    "summary(model, input_size=(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a58f9f81-f7b6-4fdb-816d-edb83e76781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "  model.train()\n",
    "  pbar = tqdm(train_loader)\n",
    "  correct = 0\n",
    "  processed = 0\n",
    "  for batch_idx, (data, target) in enumerate(pbar):\n",
    "    # get samples\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # Init\n",
    "    optimizer.zero_grad()\n",
    "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
    "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model(data)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = F.nll_loss(y_pred, target)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update pbar-tqdm\n",
    "    \n",
    "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    processed += len(data)\n",
    "\n",
    "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
    "    train_acc.append(100*correct/processed)\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    test_acc.append(100. * correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99b80b6c-4559-436f-ab1a-92e43def1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "EPOCHS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d261ea20-d492-49c4-9a4a-4d7f83c61dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.015\n",
       "    maximize: False\n",
       "    momentum: 0.9\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14bee12-c7e8-463a-9807-ba393c7235fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
